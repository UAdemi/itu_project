library(tm) #bu paketi kullandık
library(tm) #bu paketi kullandık
library(qdap)
library(qdap)
library(wordcloud)
library(viridisLite)
library(plotrix)
library(qdap)
library(tidyverse)
library(tidyverse)
library(tidytext)
library(magrittr)
library(metricsgraphics)
library(ggthemes)
library(dplyr)
library(ggplot2)
#Import Data from CSV
biden_tw <- read.csv("./archive/JoeBidenTweets.csv", stringsAsFactors = FALSE)
View(biden_tw)
trump_tw <- read.csv("./archive/realdonaldtrump.csv", stringsAsFactors = FALSE)
trump_tw1 <- read.csv("./archive/trumptweets.csv", stringsAsFactors = FALSE)
trump_tw <- read.csv("./archive/realdonaldtrump.csv", stringsAsFactors = FALSE)
trump_tw1 <- read.csv("./archive/trumptweets.csv", stringsAsFactors = FALSE)
```{r Cleaning Data}
# Isolate text from tweets
biden_tweets <- biden_tw$tweet
biden_tweets
# Make a vector source from biden_tweets
biden_source <- VectorSource(biden_tweets)
# Make a volatile corpus: biden_corpus
biden_corpus <- VCorpus(biden_source)
biden_corpus[[35]][1]
#We define a cleaning function
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(strip), char.keep=c("#", "@"))
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
biden_corpuscl <- clean_corpus(biden_corpus)
biden_corpuscl <- clean_corpus(biden_corpus)
biden_corpuscl[[39]][1]
biden_corpuscl[[35]][1]
biden_tdm <- TermDocumentMatrix(biden_corpuscl)
View(biden_tdm)
dim(biden_tdm)
# Convert biden_tdm to a matrix
biden_m <- as.matrix(biden_tdm)
biden_m
# Calculate the row sums of biden_m
term_frequency <- rowSums(biden_m)
View(term_frequency)
# Sort term_frequency in decreasing order
term_frequency <- sort(term_frequency, decreasing = TRUE)
View(term_frequency)
# View the top 10 most common words
term_frequency[1:10]
# Plot a barchart of the 10 most common words
barplot(term_frequency[1:10], col = "tan", las = 2)
# Plot a barchart of the 10 most common words
barplot(term_frequency[1:10], col = "tan", las = 2)
# View the top 10 most common words
term_frequency[1:10]
biden_corpus[[35]][1]
#We define a cleaning function
clean_corpus <- function(corpus){
biden_corpuscl <- clean_corpus(biden_corpus)
#We define a cleaning function
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(strip), char.keep="#")
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
biden_corpuscl <- clean_corpus(biden_corpus)
biden_corpuscl[[35]][1]
biden_tdm <- TermDocumentMatrix(biden_corpuscl)
# Convert biden_tdm to a matrix
biden_m <- as.matrix(biden_tdm)
# Calculate the row sums of biden_m
term_frequency <- rowSums(biden_m)
# Sort term_frequency in decreasing order
term_frequency <- sort(term_frequency, decreasing = TRUE)
# View the top 10 most common words
term_frequency[1:10]
# Plot a barchart of the 10 most common words
barplot(term_frequency[1:10], col = "tan", las = 2)
# Vector of terms
terms_vec <- names(term_frequency)
# Vector of terms
terms_vec <- names(term_frequency)
# Create a wordcloud for the values in word_freqs
wordcloud(terms_vec, term_frequency,
max.words = 50, colors = "red")
# Plot a barchart of the 10 most common words
barplot(term_frequency[1:10], col = "tan", las = 2)
# Plot a barchart of the 10 most common words
barplot(term_frequency[1:10], col = "tan", las = 2)
View(trump_tw)
library(tm) #bu paketi kullandık
library(qdap)
library(wordcloud)
library(viridisLite)
library(plotrix)
library(qdap)
library(tidyverse)
library(tidytext)
library(magrittr)
library(metricsgraphics)
library(ggthemes)
library(dplyr)
library(ggplot2)
# Plot a barchart of the 10 most common words
barplot(term_frequency[1:10], col = "tan", las = 2)
# Isolate chardonnay text from tweets
trump_tweets <- trump_tw$content
# Vector of terms
terms_vec <- names(term_frequency)
View(terms_vec)
# Create a wordcloud for the values in word_freqs
wordcloud(terms_vec, term_frequency,
max.words = 50, colors = "red")
# Isolate chardonnay text from tweets
trump_tweets <- trump_tw$content
# Make a vector source from chardonnay_tweets
trump_source <- VectorSource(trump_tweets)
# Make a volatile corpus: chardonnay_corpus
trump_corpus <- VCorpus(trump_source)
# Make a volatile corpus: chardonnay_corpus
trump_corpus <- VCorpus(trump_source)
trump_corpus[[45]][1]
trump_corpuscl <- clean_corpus(trump_corpus)
trump_corpuscl[[90]][1]
# Create a Term Document Matrix out of our cleaned data and convert it to a Matrix
trump_tdm <- TermDocumentMatrix(trump_corpuscl)
# Convert trump_tdm to a matrix
trump_m <- as.matrix(trump_tdm)
# Convert trump_tdm to a matrix
memory.limit(size= 20 Gb)
memory.limit()
memory.limit(size = 64000)
# Convert trump_tdm to a matrix
memory.limit(size= 20 Gb)
> memory.limit(size = 64000)
memory.limit(size = 64000)
# Create a Term Document Matrix out of our cleaned data and convert it to a Matrix
trump_tdm <- TermDocumentMatrix(trump_corpuscl)
# Convert trump_tdm to a matrix
trump_m <- as.matrix(trump_tdm)
# Create a Term Document Matrix out of our cleaned data and convert it to a Matrix
trump_tdm <- TermDocumentMatrix(trump_corpuscl[[90]][1])
View(trump_corpuscl)
# Create a Term Document Matrix out of our cleaned data and convert it to a Matrix
trump_tdm <- TermDocumentMatrix(trump_corpuscl[1:10])
# Convert trump_tdm to a matrix
trump_m <- as.matrix(trump_tdm)
View(trump_tdm)
# Analyzing Common Words btw Trump & Biden with commonality cloud =================================================
# Create all_coffee
all_trump <- paste(trump_tweets, collapse = " ")
# Create all_chardonnay
all_biden <- paste(biden_tweets, collapse = " ")
# Create all_tweets
all_tweets <- c(all_trump, all_biden)
View(all_tweets)
# Convert to a vector source
all_tweets <- VectorSource(all_tweets)
# Create all_corpus
all_corpus <- VCorpus(all_tweets)
# Clean the corpus
all_clean <- clean_corpus(all_corpus)
# Clean the corpus
all_clean <- clean_corpus(all_corpus)
# Create all_tdm
all_tdm <- TermDocumentMatrix(all_clean)
# Create all_m
all_m <- as.matrix(all_tdm)
# Print a commonality cloud
commonality.cloud(all_m, max.words = 100, colors = "steelblue1")
# Clean the corpus
all_clean <- clean_corpus(all_corpus)
# Create all_tdm
all_tdm <- TermDocumentMatrix(all_clean)
# Give the columns distinct names
colnames(all_tdm) <- c("Trump", "Biden")
# Create all_m
all_m <- as.matrix(all_tdm)
View(all_m)
# Create comparison cloud
comparison.cloud(all_m, colors = c("red", "blue"), max.words = 50)
top25_df <- all_m %>%
# Convert to data frame
as_tibble(rownames = "word") %>%
# Keep rows where word appears everywhere
filter_all(all_vars(. > 0)) %>%
# Get difference in counts
mutate(difference = biden - trum) %>%
# Keep rows with biggest difference
top_n(25, wt = difference) %>%
# Arrange by descending difference
arrange(desc(difference))
View(all_m)
top25_df <- all_m %>%
# Convert to data frame
as_tibble(rownames = "word") %>%
# Keep rows where word appears everywhere
filter_all(all_vars(. > 0)) %>%
# Get difference in counts
mutate(difference = Biden - Trump) %>%
# Keep rows with biggest difference
top_n(25, wt = difference) %>%
# Arrange by descending difference
arrange(desc(difference))
View(top25_df)
pyramid.plot(
# Chardonnay counts
top25_df$chardonnay,
# Coffee counts
top25_df$coffee,
# Words
labels = top25_df$word,
top.labels = c("Biden", "Words", "Trump"),
main = "Words in Common",
unit = NULL,
gap = 8,
)
pyramid.plot(
# Chardonnay counts
top25_df$Biden,
# Coffee counts
top25_df$Trump,
# Words
labels = top25_df$word,
top.labels = c("Biden", "Words", "Trump"),
main = "Words in Common",
unit = NULL,
gap = 8,
)
# Word association
word_associate(biden_tweets, match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
pyramid.plot(
# Chardonnay counts
top25_df$Biden,
# Coffee counts
top25_df$Trump,
space = 1,
# Words
labels = top25_df$word,
top.labels = c("Biden", "Words", "Trump"),
main = "Words in Common",
unit = NULL,
gap = 8,
)
pyramid.plot(
# Chardonnay counts
top25_df$Biden,
# Coffee counts
top25_df$Trump,
space = 0,
# Words
labels = top25_df$word,
top.labels = c("Biden", "Words", "Trump"),
main = "Words in Common",
unit = NULL,
gap = 8,
)
pyramid.plot(
# Chardonnay counts
top25_df$Biden,
# Coffee counts
top25_df$Trump,
space = -1,
# Words
labels = top25_df$word,
top.labels = c("Biden", "Words", "Trump"),
main = "Words in Common",
unit = NULL,
gap = 8,
)
pyramid.plot(
# Chardonnay counts
top25_df$Biden,
# Coffee counts
top25_df$Trump,
space = 0,
# Words
labels = top25_df$word,
top.labels = c("Biden", "Words", "Trump"),
main = "Words in Common",
unit = NULL,
gap = 8,
)
pyramid.plot(
# Chardonnay counts
top25_df$Biden,
# Coffee counts
top25_df$Trump,
space = 0,
gap = 1,
# Words
labels = top25_df$word,
top.labels = c("Biden", "Words", "Trump"),
main = "Words in Common",
unit = NULL,
gap = 8,
)
# Word association
word_associate(biden_tweets[1:100], match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
# Word association
word_associate(biden_tweets[1:1000], match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
# Word association
word_associate(biden_tweets[1:500], match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
# Word association
word_associate(biden_tweets[1:550], match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
# Word association
word_associate(biden_tweets[1:800], match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
# Word association
word_associate(biden_tweets[1:900], match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
# Word association
word_associate(biden_tweets[1:1000], match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
# Word association
word_associate(biden_tweets[1:999], match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
# Add “donald” and “president” to the list: new_stops
new_stops <- c(“donald”, “president”, stopwords("en"))
library(qdap)
library(tm) #bu paketi kullandık
library(qdap)
library(wordcloud)
library(viridisLite)
library(plotrix)
library(qdap)
library(tidyverse)
library(tidytext)
library(magrittr)
library(metricsgraphics)
library(ggthemes)
library(dplyr)
library(ggplot2)
# Add “donald” and “president” to the list: new_stops
new_stops <- c("donald", "president", stopwords("en"))
# Remove stop words from text
biden_tweets_nt <- removeWords(biden_tweets, new_stops)
# Word association
word_associate(biden_tweets[1:999], match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
# Word association
word_associate(biden_tweets_nt, match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
# Word association
word_associate(biden_tweets_nt[1:1000], match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
# Add “donald” and “president” to the list: new_stops
new_stops <- c("donald", "my", "along", "and" "president", stopwords("en"))
# Add “donald” and “president” to the list: new_stops
new_stops <- c("donald", "my", "along", "and", "president", stopwords("en"))
# Remove stop words from text
biden_tweets_nt <- removeWords(biden_tweets, new_stops)
# Word association
word_associate(biden_tweets_nt[1:1000], match.string = "Trump",
network.plot = TRUE, cloud.colors = c("gray85", "darkred"))
